{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок теоретических вопросов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Пусть мы решаем задачу множественной классификации для разметки 4 уникальных лейблов (классов). Выберите верное утверждение про количество базовых моделей в подходах OneVsOne и OneVsRest*: \n",
    "\n",
    "1. Для использования OneVsOne придется обучить 4 базовых модели, а для подхода OneVsRest 6.\n",
    "2. Для использования OneVsOne придется обучить 6 базовых модели, а для подхода OneVsRest 4.\n",
    "3. Для использования OneVsOne придется обучить 4 базовых модели, а для подхода OneVsRest 4.\n",
    "4. Для использования OneVsOne придется обучить 6 базовых модели, а для подхода OneVsRest 6.\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** Для каждой пары $(i, j)$ из возможных классов в OneVsOne строится по модели бинарной лкассификации. Среди 4 лейблов таких пар найдется ровно 6 уникальных: $(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)$! В случае OneVsRest все проще - посмотрим на количество лейблов!\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Выберите верные утверждения относительно подходов микро- и макроусреднения*: \n",
    "\n",
    "1.\tПри микро-усреднении вклад каждого класса в итоговую метрику одинаков.\n",
    "2.\tПри микро-усреднении вклад каждого класса в итоговую метрику пропорционален размеру данного класса.\n",
    "3.\tПри макро-усреднении вклад каждого класса в итоговую метрику одинаков.\n",
    "4.\tПри макро-усреднении вклад каждого класса в итоговую метрику пропорционален размеру данного класса.\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2, 3)** Макро-усреднение, в отличие от микро-, усредняет уже нечувствительные к дисбалансу классов метрики. Поэтому вклад и одинаков.\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок практики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем работать с данными агрегатора такси [Sigma Cabs](https://www.kaggle.com/datasets/arashnic/taxi-pricing-with-mobility-analytics). В зависимости от характеристик поездки требуется предсказать один из трех типов повышенного ценообразования: [1, 2, 3]. Таким образом, это поможет компании оптимально мэтчить такси и клиентов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sigma_cabs.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Занесем индекс колонку\n",
    "df = df.set_index('Trip_ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание признаков:\n",
    "\n",
    "1. **Trip_ID**: ID for TRIP\n",
    "2. **Trip_Distance**: The distance for the trip requested by the customer\n",
    "3. **TypeofCab**: Category of the cab requested by the customer\n",
    "4. **CustomerSinceMonths**: Customer using cab services since n months; 0 month means current month\n",
    "5. **LifeStyleIndex**: Proprietary index created by Sigma Cabs showing lifestyle of the customer based on their behaviour\n",
    "6. **ConfidenceLifeStyle_Index**: Category showing confidence on the index mentioned above\n",
    "7. **Destination_Type**: Sigma Cabs divides any destination in one of the 14 categories.\n",
    "8. **Customer_Rating**: Average of life time ratings of the customer till date\n",
    "9. **CancellationLast1Month**: Number of trips cancelled by the customer in last 1 month\n",
    "10. **Var1**, **Var2** and **Var3**: Continuous variables masked by the company. Can be used for modelling purposes\n",
    "11. **Gender**: Gender of the customer\n",
    "\n",
    "**SurgePricingType**: Target (can be of 3 types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA \n",
    "Заполните пропуски в вещественных признаках медианой, а в категориальных - самым популярным классом. Изобразите марицу корреляций и выведите топ5 пар самых коррелированных признаков.\n",
    "\n",
    "Так как в сумме уникальных значений различных категориальных признаков окажется не супер-много, примените `One-Hot-Encoding` для них. Не забудьте в методе `pd.get_dummies` указать параметр `drop_first=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Помотрим на баланс классов\n",
    "df['Surge_Pricing_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Пропущенные переменные в вещественных признаках\n",
    "num_cols = df.select_dtypes(exclude='object').columns\n",
    "df[num_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним медианой\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.title(\"Correaltion heatmap\")\n",
    "sns.heatmap(df[num_cols].corr(), cmap='inferno');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "get_top_abs_correlations(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Пропуски в категориальных заполним самым популярным значением\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Не так много классов, можно юзать OHE\n",
    "df.select_dtypes('object').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закодируем категориальные признаки\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "X = df.drop('Surge_Pricing_Type', axis=1)\n",
    "y = df['Surge_Pricing_Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2022)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Разобьем на трейн-тест\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, \n",
    "                                                     test_size=0.2, \n",
    "                                                     shuffle=True, \n",
    "                                                     random_state=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.** Обучите One-vs-Rest Logreg. Посчитайте precision, recall, f1-score и усредните по всем классам с помощью micro, macro и weighted avg. Здесь и далее округляйте до 3 знака после запятой.\n",
    "\n",
    "Чтобы отдельно и долго не вычислять метрики, можно воспользоваться `classification_report` из `sklearn.metrics`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Обучение\n",
    "logit = LogisticRegression()\n",
    "pipe1 = Pipeline([('scaler', StandardScaler()), \n",
    "                  ('one_vs_all', OneVsRestClassifier(logit))])\n",
    "\n",
    "pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pipe1.predict(X_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите оптимальные гиперпараметры модели с помощью `GridSearchCV()` из предложенных. Для лучшего набора гиперпараметров посчитайте те же самые метрики. Валидировать параметры необходимо по `accuracy`. В этот раз проведем настояющую процедуру Кросс-Валидации! \n",
    "\n",
    "Для этого в метод `fit` передадим тренировочную часть наших данных, в параметр `cv` ничего не будем передавать (по дефолту 5-fold Кросс-Валидация будет проведена), а итоговые метрики замерим на тесте!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'one_vs_all__estimator__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'one_vs_all__estimator__C': [0.001, 0.01, 0.1, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор параметров\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid1 = GridSearchCV(pipe1, param_grid, cv=5)\n",
    "grid1.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid1.best_params_}\")\n",
    "print(classification_report(y_test, grid1.predict(X_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразите три калибровочные кривые для Logistic Classifier: 0-vs-rest, 1-vs-rest, 2-vs-rest. Хорошо ли откалиброван обученный классификатор? \n",
    "\n",
    "-- *Кривые достаточно близки к диагонали! Хорошо откалиброван.*\n",
    "\n",
    "Заметьте, что `predict_proba` возвращает список из вероятностей для всех наших классов!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закодируем таргет \n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "y_ohe = ohe.fit_transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "\n",
    "# Калибровочные кривые\n",
    "for label in range(3):\n",
    "    prob_pos = grid1.predict_proba(X_test)[:, label]\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(y_ohe[:, label],\n",
    "                                                                    prob_pos,\n",
    "                                                                    n_bins=15)\n",
    "    plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=f\"{label} vs Rest\")\n",
    "\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.xlabel(\"Mean predicted value\")\n",
    "plt.title('Logistic OVR Calibration curves')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.** Обучите логистическую регрессию с гиперпараметрами из первого задания на полиномиальных признаках до 4 степени. Сравните метрики с первым заданием.\n",
    "\n",
    "\n",
    "Пример: Пусть у нас был единственный признак \n",
    "\n",
    "$$\n",
    "d_j = [1, 2, 3, 4]\n",
    "$$\n",
    "\n",
    "Тогда полиномиальные признаки до 4 степени от такого будут иметь вид:\n",
    "\n",
    "$$\n",
    "d_j^1 = [1, 2, 3, 4]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_j^2 = [1, 4, 9, 16]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_j^3 = [1, 8, 27, 64]\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_j^4 = [1, 16, 81, 256]\n",
    "$$\n",
    "\n",
    "P.S. Бинарные колонки нет смысла возводить в какие-то степени, поэтому возьмем исключительно вещественные из базовых. \n",
    "\n",
    "Для этого можно воспользоваться классическим циклом (или уроком из занятия про `Sberbank Housing Market`).\n",
    "\n",
    "P.S.S Зачастую еще, создаваю полиномиальные фичи, учитывают \"пересечения\" признаков, то есть, например, из векторов признаков $d_j, d_i$ генерируют не просто новые степени $d_j^2, d_i^2, d_j^3, d_i^3...$, а еще и признаки вида $d_j \\cdot d_i, d_j^2 \\cdot d_i, d_j \\cdot d_i^2...$, но здесь ограничьтесь просто степенями!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание полиномиальных признаков\n",
    "X_polinomial = X.copy()\n",
    "\n",
    "\n",
    "for col in num_cols.drop('Surge_Pricing_Type'):\n",
    "    data_part = pd.concat([X[col]**(1+i) for i in range(4)], axis=1)\n",
    "    data_part.columns = [col + f\"_power_{i+1}\" for i in range(4)]\n",
    "    \n",
    "    X_polinomial = X_polinomial.drop(col, axis=1)\n",
    "    X_polinomial = pd.concat((X_polinomial, data_part), axis=1)\n",
    "    \n",
    "X_polinomial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pol_train, X_pol_test, y_train, y_test  = train_test_split(X_polinomial, y, \n",
    "                                                             test_size=0.2, \n",
    "                                                             shuffle=True, \n",
    "                                                             random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(C=0.001, penalty='l2')\n",
    "pipe2 = Pipeline([('scaler', StandardScaler()), \n",
    "                  ('one_vs_all', OneVsRestClassifier(logit))])\n",
    "\n",
    "pipe2.fit(X_pol_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, pipe2.predict(X_pol_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогии с первым заданием изобразите три калибровочные кривые. Стало ли лучше?\n",
    "\n",
    "-- *Неоднозначно*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Закодируем таргет \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "y_ohe = ohe.fit_transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "\n",
    "# Калибровочные кривые\n",
    "for label in range(3):\n",
    "    prob_pos = pipe2.predict_proba(X_pol_test)[:, label]\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(y_ohe[:, label], prob_pos, n_bins=15)\n",
    "    plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=f\"{label} vs Rest\")\n",
    "\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.xlabel(\"Mean predicted value\")\n",
    "plt.title('Logistic OVR Calibration curves')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.** Обучите на датасете без полиномиальных признаков One-vs-One `SGDClassifier` из `sklearn.linear_model`, который использует стохастический градиентный спуск (узнаете о нем позже) и может обучать как `SVM`, так и, например, `LogReg`, если указать в качестве параметра `loss` либо `hinge`, либо `log` соответственно!\n",
    "\n",
    "Посчитайте precision, recall, f1-score и усредните по всем классам с помощью micro, macro и weighted avg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, \n",
    "                                                     test_size=0.2, \n",
    "                                                     shuffle=True, \n",
    "                                                     random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "# Обучение\n",
    "pipe_ovo = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('one_vs_one', OneVsOneClassifier(SGDClassifier()))])\n",
    "\n",
    "pipe_ovo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pipe_ovo.predict(X_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите оптимальные гиперпараметры модели с помощью `GridSearchCV()`. При этом переберите всевозможные функции потерь. Таким образом, при `loss = 'hinge'`, мы обучим SVM, при `loss = 'log'` мы обучим логистическую регрессию и т.д.\n",
    "\n",
    "Используйте прием с Кросс-Валидацией при подборе параметров, как ранее, а также замерьте метрики на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'one_vs_one__estimator__loss': ['hinge', 'log', 'modified_huber'],\n",
    "              'one_vs_one__estimator__penalty': ['l1', 'l2'],\n",
    "              'one_vs_one__estimator__alpha': [0.001, 0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "grid_ovo = GridSearchCV(pipe_ovo, param_grid, cv=5)\n",
    "grid_ovo.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_ovo.best_params_}\")\n",
    "print(classification_report(y_test, grid_ovo.predict(X_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно ли однозначной сказать, какой подход оказался лучше: One-vs-Rest или One-vs-One?\n",
    "\n",
    "-- *Кажется, что у каждого подхода есть свои плюсы и минусы. Хотя в МО обычно опираются на качество работы алгоритмов, и если оно существенное, то можно однозначно сказать, какой из них лучше*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

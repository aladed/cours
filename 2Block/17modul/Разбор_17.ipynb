{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок теоретических вопросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Зачем мы взвешиваем энтропию по количеству попавших в вершину объектов?*: \n",
    "\n",
    "1. Для того, чтобы быстрее находить признаки для разбиения.\n",
    "2. Для того, чтобы не было ужасных разбиений, выбранных в силу того, что в хорошей вершине оказалось очень мало объектов (например, верно разметили единственную точку).\n",
    "3. Без взвешивания дерево не сможет оптимально, с точки зрения ошибки на обучающей выборке, подогнаться под данные\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** В действительности, на лекции разбирали похожий случай. При выборе лучшего предиката стоит учитывать долю объектов, которые отправляются в левую и правую вершины.\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Если увеличивать обязательное количество объектов в получившейся вершине при разбиении, то логично предположить, что*: \n",
    "\n",
    "1.\tОшибка на обучающей и тестовых выборках будет падать\n",
    "2.\tОшибка на обучающей выборке будет увеличиваться, а на тестовой падать до какого-то момента\n",
    "3.\tНельзя точно определить\n",
    "4.\tОшибка на тестовой выборке будет падать, насчет ошибки на обучающей выборке нельзя сказать точно\n",
    "\n",
    "\n",
    "**Ответ: 2)** Если наше требование к количеству объектов в вершинах будет достаточно лояльным (скажем, не будет ограничений), то дерево окажется очень глубоким и переобучится. Ужесточение этого требования помогает решить эту проблему.\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*В каком случае дерево не сможет выдать на обучающей выборке 100-процентное качество (ограничений на глубину и другие гиперпараметры нет)?*: \n",
    "\n",
    "1.\tЕсли зависимость между данными и таргетом слишком сложная для данного алгоритма\n",
    "2.\tПо своей сути решающее дерево не гарантирует стопроцентное качество на обучающей выборке \n",
    "3.\tЕсли используется неподходящий для этих данных критерий хаотичности  \n",
    "4.\tЕсли попадутся идентичные объекты с разными таргетами\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 4)** На практике часто случается, что у одного того же объекта (или просто у идентичных объектов в нашем признаковом пространстве) разное значение таргета. Например, тот же самый клиент может либо кликать на рекламный банер, либо не кликать. В таком случае, как бы мы ни старались, для такого объекта нельзя будет иметь нулевую ошибку, так как он будет иметь 2 различных таргета, а предсказываем мы в классических задачах только один.\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок практики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Colormap, ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Создадим синтетический датасет\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=200, n_features=2,\n",
    "    n_informative=2, n_redundant=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "data = pd.DataFrame(np.hstack((X, y.reshape(-1, 1))),\n",
    "                    columns=['x1', 'x2', 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__\n",
    "\n",
    "Обучите решающее дерево с параметрами по умолчанию, предварительно разбив выборку на обучающую и тестовую. Постройте разделяющую поверхность на трейне (для этого воспользуйтесь функцией `plot_surface`, пример ниже). Посчитайте accuracy на обучающей и тестовой выборках. Сильно ли деревья переобучились? (2б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surface(clf, X, y):\n",
    "    plot_step = 0.01\n",
    "    palette = sns.color_palette(n_colors=len(np.unique(y)))\n",
    "    cmap = ListedColormap(palette)\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cmap, alpha=0.3)\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, alpha=.7,\n",
    "                edgecolors=np.array(palette)[y], linewidths=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Разделим выборку\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Обучим дерево и нарисуем разделенную поверхность\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(16, 10)\n",
    "\n",
    "plot_surface(tree, X_train, y_train)\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Разделяющая поверхность\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Замерим качество работы\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_acc = accuracy_score(y_train, tree.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, tree.predict(X_test))\n",
    "print('train_acc = ', train_acc, 'test_acc = ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__\n",
    "\n",
    "Переберите несколько параметров для регуляризации (`max_depth`, `min_samples_leaf`) из предложенных. Для каждого набора гиперпараметров постройте разделяющую поверхность, выведите обучающую и тестовую ошибки. Используйте, если хотите, функцию ниже. Как изменение параметров влияет на поверхность? При каких параметрах на тесте достигается лучшее качество? А на трейне? (2б)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surface_axes(clf, X, y, ax, train_acc, test_acc):\n",
    "    plot_step = 0.01\n",
    "    palette = sns.color_palette(n_colors=len(np.unique(y)))\n",
    "    cmap = ListedColormap(palette)\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cmap, alpha=0.3)\n",
    "\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, alpha=.7,\n",
    "    edgecolors=np.array(palette)[y], linewidths=2)\n",
    "    \n",
    "    ax.plot([], [], label = 'train_acc : %0.5f' % train_acc)\n",
    "    ax.plot([], [], label = 'test_acc : %0.5f' % test_acc)\n",
    "    \n",
    "    plt.legend(loc = 'lower right', prop={'size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Зададим сетку гиперпараметров\n",
    "\n",
    "max_depth_set = [6, 7, 8, 9, 12]\n",
    "\n",
    "min_samples_leaf_set = [3, 5, 7, 10]\n",
    "\n",
    "### Разделим выборку\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Для разных комбинаций гиперпараметров\n",
    "### Замерим качество и нарисуем поверхность\n",
    "\n",
    "for max_depth in max_depth_set:\n",
    "\n",
    "    i = 1 \n",
    "\n",
    "    f = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    for min_samples_leaf in min_samples_leaf_set:\n",
    "    \n",
    "        tree = DecisionTreeClassifier(max_depth = max_depth, min_samples_leaf=min_samples_leaf).fit(X_train, y_train)\n",
    "\n",
    "        ax = f.add_subplot(1, 4, i)\n",
    "        \n",
    "        train_acc = accuracy_score(y_train, tree.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test, tree.predict(X_test))\n",
    "        \n",
    "        plot_surface_axes(tree, X_train, y_train, ax, train_acc, test_acc)\n",
    "    \n",
    "      \n",
    "        plt.title('max_depth={}, min_samples_leaf={}'.format(max_depth, min_samples_leaf))\n",
    "    \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 3.__\n",
    "\n",
    "Добавим признак $2\\cdot x_1 - x_2$, транформацию добавим как шаг пайплайна. С помощью данного класса обучите дерево с максимальной глубиной=3, нарисуйте поверхность на трейне, посчитайте accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomFunctionTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, first_col, second_col, function):\n",
    "        self.first_col = first_col\n",
    "        self.second_col = second_col\n",
    "        self.function = function\n",
    "        print(\"Инициализировали класс!\")\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        print(\"Зафитили датасет!\")\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        X_ = X.copy()\n",
    "        X_['new_feature'] = self.function(X_[self.first_col], X_[self.second_col])\n",
    "        X_ = X_.drop([self.first_col, self.second_col], axis=1)\n",
    "        \n",
    "        print(\"Трансформировали датасет!\")\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=['x1', 'x2'])\n",
    "X_test = pd.DataFrame(X_test, columns=['x1', 'x2'])\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([(\"custom_transformer\", CustomFunctionTransformer(\"x1\",\n",
    "                                                                  \"x2\",\n",
    "                                                                  lambda x,y: 2*x-y)),\n",
    "                 (\"decision_tree\", DecisionTreeClassifier(max_depth=3))])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(16, 10) \n",
    "\n",
    "### Вычислим границы признакового пространства\n",
    "\n",
    "pixel_step = 0.001\n",
    "\n",
    "x1_min, x1_max = X_train.values[:, 0].min() - 1, X_train.values[:, 0].max() + 1\n",
    "x2_min, x2_max = X_train.values[:, 1].min() - 1, X_train.values[:, 1].max() + 1\n",
    "\n",
    "### Генерим много-много точек на плоскости\n",
    "\n",
    "xx1, xx2 = np.meshgrid(\n",
    "    np.arange(x1_min, x1_max, pixel_step),\n",
    "    np.arange(x2_min, x2_max, pixel_step)\n",
    ")\n",
    "\n",
    "### Для каждой точки даем прогноз, чтобы покрыть поверхности\n",
    "\n",
    "Z = pipe.predict(pd.DataFrame(np.c_[xx1.ravel(), xx2.ravel()], columns=[\"x1\", \"x2\"]))\n",
    "Z = Z.reshape(xx1.shape)\n",
    "\n",
    "# Заполняем пространство\n",
    "\n",
    "cs = plt.contourf(xx1, xx2, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "### Рисуем точечки и обученные области\n",
    "\n",
    "for i, n, c in zip(range(2), pipe.classes_, [\"#FF5533\", \"#00B050\"]):\n",
    "    idx = np.where(y_train == i)\n",
    "    plt.scatter(\n",
    "        X_train.values[idx, 0],\n",
    "        X_train.values[idx, 1],\n",
    "        c=c,\n",
    "        s=20,\n",
    "        edgecolor=\"k\",\n",
    "        label=\"Class %s\" % n,\n",
    "    )\n",
    "    \n",
    "plt.xlim(x1_min, x1_max)\n",
    "plt.ylim(x2_min, x2_max)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Decision Boundary\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = accuracy_score(y_train, pipe.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, pipe.predict(X_test))\n",
    "print('train_acc = ', train_acc, 'test_acc = ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, стало немного красивее! :)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8db21564b35bbdf2f1295d2e540489014671416f5dc577a5b9d4ca56833a3713"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
